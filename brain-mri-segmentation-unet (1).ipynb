{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import needed modules","metadata":{}},{"cell_type":"code","source":"pip install -U pip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U scikit-image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U scikit-image[optional]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport random\nimport pathlib\nimport itertools\nfrom glob import glob\nfrom tqdm import tqdm_notebook, tnrange\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.color import rgb2gray\n#from skimage.morphology import label\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread, imshow, concatenate_images\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create needed functions","metadata":{}},{"cell_type":"markdown","source":"**Function to create dataframe from dataset**","metadata":{}},{"cell_type":"code","source":"# function to create dataframe\ndef create_df(data_dir):\n    images_paths = []\n    masks_paths = glob(f'{data_dir}/*/*_mask*')\n\n    for i in masks_paths:\n        images_paths.append(i.replace('_mask', ''))\n\n    df = pd.DataFrame(data= {'images_paths': images_paths, 'masks_paths': masks_paths})\n\n    return df\n\n# Function to split dataframe into train, valid, test\ndef split_df(df):\n    # create train_df\n    train_df, dummy_df = train_test_split(df, train_size= 0.8)\n\n    # create valid_df and test_df\n    valid_df, test_df = train_test_split(dummy_df, train_size= 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Function to create image generators and augmentation**","metadata":{}},{"cell_type":"code","source":"def create_gens(df, aug_dict):\n    img_size = (256, 256)\n    batch_size = 40\n\n\n    img_gen = ImageDataGenerator(**aug_dict)\n    msk_gen = ImageDataGenerator(**aug_dict)\n\n    # Create general generator\n    image_gen = img_gen.flow_from_dataframe(df, x_col='images_paths', class_mode=None, color_mode='rgb', target_size=img_size,\n                                            batch_size=batch_size, save_to_dir=None, save_prefix='image', seed=1)\n\n    mask_gen = msk_gen.flow_from_dataframe(df, x_col='masks_paths', class_mode=None, color_mode='grayscale', target_size=img_size,\n                                            batch_size=batch_size, save_to_dir=None, save_prefix= 'mask', seed=1)\n    gen = zip(image_gen, mask_gen)\n\n    for (img, msk) in gen:\n        img = img / 255\n        msk = msk / 255\n        msk[msk > 0.5] = 1\n        msk[msk <= 0.5] = 0\n\n        yield (img, msk)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function that have Unet structure","metadata":{}},{"cell_type":"code","source":"def unet(input_size=(256, 256, 3)):\n    inputs = Input(input_size)\n\n    # First DownConvolution / Encoder Leg will begin, so start with Conv2D\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(inputs)\n    bn1 = Activation(\"relu\")(conv1)\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation(\"relu\")(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(pool1)\n    bn2 = Activation(\"relu\")(conv2)\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation(\"relu\")(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(pool2)\n    bn3 = Activation(\"relu\")(conv3)\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation(\"relu\")(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(pool3)\n    bn4 = Activation(\"relu\")(conv4)\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation(\"relu\")(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(pool4)\n    bn5 = Activation(\"relu\")(conv5)\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation(\"relu\")(bn5)\n\n    up6 = concatenate([Conv2DTranspose(512, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn5), conv4], axis=3)\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(up6)\n    bn6 = Activation(\"relu\")(conv6)\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation(\"relu\")(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn6), conv3], axis=3)\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(up7)\n    bn7 = Activation(\"relu\")(conv7)\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation(\"relu\")(bn7)\n    up8 = concatenate([Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn7), conv2], axis=3)\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(up8)\n    bn8 = Activation(\"relu\")(conv8)\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation(\"relu\")(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn8), conv1], axis=3)\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(up9)\n    bn9 = Activation(\"relu\")(conv9)\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation(\"relu\")(bn9)\n\n    conv10 = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(bn9)\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions for coefficients and loss","metadata":{}},{"cell_type":"code","source":"# function to create dice coefficient\ndef dice_coef(y_true, y_pred, smooth=100):\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n\n    intersection = K.sum(y_true_flatten * y_pred_flatten)\n    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n    return (2 * intersection + smooth) / (union + smooth)\n\n# function to create dice loss\ndef dice_loss(y_true, y_pred, smooth=100):\n    return -dice_coef(y_true, y_pred, smooth)\n\n# function to create iou coefficient\ndef iou_coef(y_true, y_pred, smooth=100):\n    intersection = K.sum(y_true * y_pred)\n    sum = K.sum(y_true + y_pred)\n    iou = (intersection + smooth) / (sum - intersection + smooth)\n    return iou","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function to show images sample","metadata":{}},{"cell_type":"code","source":"def show_images(images, masks):\n    plt.figure(figsize=(12, 12))\n    for i in range(25):\n        plt.subplot(5, 5, i+1)\n        img_path = images[i]\n        mask_path = masks[i]\n        # read image and convert it to RGB scale\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # read mask\n        mask = cv2.imread(mask_path)\n        # sho image and mask\n        plt.imshow(image)\n        plt.imshow(mask, alpha=0.4)\n\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function to display training history","metadata":{}},{"cell_type":"code","source":"def plot_training(hist):\n    '''\n    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n    '''\n\n    # Define needed variables\n    tr_acc = hist.history['accuracy']\n    tr_iou = hist.history['iou_coef']\n    tr_dice = hist.history['dice_coef']\n    tr_loss = hist.history['loss']\n\n    val_acc = hist.history['val_accuracy']\n    val_iou = hist.history['val_iou_coef']\n    val_dice = hist.history['val_dice_coef']\n    val_loss = hist.history['val_loss']\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n    index_iou = np.argmax(iou_coef)\n    iou_highest = val_iou[index_iou]\n    index_dice = np.argmax(dice_coef)\n    dice_highest = val_dice[index_dice]\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n\n    Epochs = [i+1 for i in range(len(tr_acc))]\n\n    acc_label = f'best epoch= {str(index_acc + 1)}'\n    iou_label = f'best epoch= {str(index_iou + 1)}'\n    dice_label = f'best epoch= {str(index_dice + 1)}'\n    loss_label = f'best epoch= {str(index_loss + 1)}'\n    # Plot training history\n    plt.figure(figsize= (20, 20))\n    plt.style.use('fivethirtyeight')\n\n    # Training Accuracy\n    plt.subplot(2, 2, 1)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n# Training IoU\n    plt.subplot(2, 2, 2)\n    plt.plot(Epochs, tr_iou, 'r', label= 'Training IoU')\n    plt.plot(Epochs, val_iou, 'g', label= 'Validation IoU')\n    plt.scatter(index_iou + 1 , iou_highest, s= 150, c= 'blue', label= iou_label)\n    plt.title('Training and Validation IoU Coefficient')\n    plt.xlabel('Epochs')\n    plt.ylabel('IoU')\n    plt.legend()\n\n    # Training Dice\n    plt.subplot(2, 2, 3)\n    plt.plot(Epochs, tr_dice, 'r', label= 'Training Dice')\n    plt.plot(Epochs, val_dice, 'g', label= 'Validation Dice')\n    plt.scatter(index_dice + 1 , dice_highest, s= 150, c= 'blue', label= dice_label)\n    plt.title('Training and Validation Dice Coefficient')\n    plt.xlabel('Epochs')\n    plt.ylabel('Dice')\n    plt.legend()\n\n    # Training Loss\n    plt.subplot(2, 2, 4)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Structure","metadata":{}},{"cell_type":"markdown","source":"**Start reading data**","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/lgg-mri-segmentation/kaggle_3m'\n\ndf = create_df(data_dir)\ntrain_df, valid_df, test_df = split_df(df)\n\n\ntr_aug_dict = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\n\n\ntrain_gen = create_gens(train_df, aug_dict=tr_aug_dict)\nvalid_gen = create_gens(valid_df, aug_dict={})\ntest_gen = create_gens(test_df, aug_dict={})\nshow_images(list(train_df['images_paths']), list(train_df['masks_paths']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Unet Model**","metadata":{}},{"cell_type":"code","source":"model = unet()\nmodel.compile(Adamax(learning_rate= 0.001), loss= dice_loss, metrics= ['accuracy', iou_coef, dice_coef])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model training**","metadata":{}},{"cell_type":"code","source":"epochs = 120\nbatch_size = 40\ncallbacks = [ModelCheckpoint('unet.hdf5', verbose=0, save_best_only=True)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(train_df) / batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    callbacks=callbacks,\n                    validation_data = valid_gen,\n                    validation_steps=len(valid_df) / batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint(\"Train IoU: \", train_score[2])\nprint(\"Train Dice: \", train_score[3])\nprint('-' * 20)\n\nprint(\"Valid Loss: \", valid_score[0])\nprint(\"Valid Accuracy: \", valid_score[1])\nprint(\"Valid IoU: \", valid_score[2])\nprint(\"Valid Dice: \", valid_score[3])\nprint('-' * 20)\n\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])\nprint(\"Test IoU: \", test_score[2])\nprint(\"Test Dice: \", test_score[3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"for _ in range(20):\n    index = np.random.randint(1, len(test_df.index))\n    img = cv2.imread(test_df['images_paths'].iloc[index])\n    img = cv2.resize(img, (256, 256))\n    img = img/255\n    img = img[np.newaxis, :, :, : ]\n\n    predicted_img = model.predict(img)\n\n    plt.figure(figsize=(12, 12))\n    \n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img))\n    plt.axis('off')\n    plt.title('Original Image')\n\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(test_df['masks_paths'].iloc[index])))\n    plt.axis('off')\n    plt.title('Original Mask')\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(predicted_img) > 0.5 )\n    plt.title('Prediction')\n    plt.axis('off')\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you found it helpful, do upvote\n\nFeel free to comment\n\nI would love to have suggestions.","metadata":{}}]}